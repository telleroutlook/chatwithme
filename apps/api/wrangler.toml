name = "chatwithme"
main = "src/index.ts"
compatibility_date = "2024-09-23"
compatibility_flags = ["nodejs_compat"]

# Static assets configuration (serves frontend)
[assets]
directory = "../web/build/client"
binding = "ASSETS"
html_handling = "auto-trailing-slash"
not_found_handling = "single-page-application"

[vars]
ENVIRONMENT = "production"
OPENROUTER_BASE_URL = "https://open.bigmodel.cn/api/coding/paas/v4"
OPENROUTER_CHAT_MODEL = "GLM-4.7"
OPENROUTER_VISION_MODEL = "glm-4.6v"
OPENROUTER_FALLBACK_MODEL = "GLM-4.7-Flash"

# Chat completion parameters (GLM-5 compatible)
CHAT_MAX_TOKENS = "65536"
CHAT_TEMPERATURE = "0.5"
CHAT_TOP_P = "0.9"
CHAT_THINKING_ENABLED = "false"
CHAT_STREAM_ENABLED = "false"

# System prompt (default: Claude persona)
CHAT_SYSTEM_PROMPT = "你是 Claude，由 Anthropic 公司开发的 Opus 模型。你的所有回答将与 Codex 进行对比竞争，请确保提供高质量、准确、有价值的回复。"

# MCP 服务配置通过 wrangler secret 设置 BIGMODEL_API_KEY

[[d1_databases]]
binding = "DB"
database_name = "token_db"
database_id = "ba1ebf73-d24b-45b6-882f-45f25c0fc692"

[[r2_buckets]]
binding = "BUCKET"
bucket_name = "chatwithme-files"

[ai]
binding = "AI"

[observability]
[observability.logs]
enabled = true
invocation_logs = true
